{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1884b1d",
   "metadata": {},
   "source": [
    "![title_pic](./img/title_page.png)\n",
    "#### TV & Movie recommendation system using a collaborative and content based filtering approach\n",
    "\n",
    "# Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f6ac8",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "The main goal for this project is to Develop a hybrid movie/TV recommendation system that combines collaborative filtering and content-based filtering to suggest new content to users. Currently, these techniques are applied independently. Our project aims to harness their combined potential.\n",
    "\n",
    "**Collaborative Filtering**: Analyzes existing user profiles to discover shared preferences and recommend new content based on similarities.\n",
    "\n",
    "**Content-Based Filtering**: Suggests new content with similar fearures to the movie/TV show that you input.\n",
    "\n",
    "\n",
    "# Business Understanding\n",
    "As streaming platforms pile-up content, users struggle to pinpoint films or shows that align with their tastes. The dubious presence of bias in platform algorithms exacerbates this challenge, making it harder for users to rely on platform recommendations. Biases emerge from factors like skewed user preferences, popularity bias, or even the platform's promotional agenda. As a result, recommended content may not cater to users' unique tastes, negatively affecting the overall user experience.\n",
    "\n",
    "Streaming platforms stand to gain from implementing an unbiased hybrid recommendation system that blends content-based and collaborative filtering techniques. This approach leverages the best of both methods, increasing reliability and personalization while mitigating biases. The content-based technique analyzes features like genre and content description, while collaborative filtering harnesses the collective trends of user ratings. Together, they forge a powerful recommendation engine, enhancing user satisfaction and overall experience.\n",
    "\n",
    "# Collaborative Filtering\n",
    "\n",
    "In the collaborative filtering approach, we focused on user-to-user filtering, comparing users' profiles to identify similarities in movie preferences by looking at the ratings they gave to movies that they have both watched. We started by creating a base model as a benchmark, which predicted the mean rating for each movie. To improve the recommendations, we iterated over two models: an SVD model and an SVDpp model. In the iteration process, we used cross-validation in tandem with GridSearchCV to find the best parameters for our models, optimizing their performance.\n",
    "\n",
    "This cross-validation and GridSearchCV process helped us fine-tune our models to achieve a Root Mean Square Error (RMSE) score of 0.908. Given that our dataset contains user ratings on a scale of 1 to 5, a 0.908 RMSE score signifies good performance in predicting users' movie ratings. It indicates that, on average, our model's predictions deviate by 0.908 from the actual user ratings. This performance enables more accurate and personalized recommendations for users based on their shared preferences, enhancing the overall user experience and satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849d49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from surprise.prediction_algorithms import BaselineOnly, SVDpp, SVD\n",
    "\n",
    "\n",
    "# increasing display to view large descriptions and reviewText\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dab591a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A3JVF9Y53BEOGC</td>\n",
       "      <td>000503860X</td>\n",
       "      <td>I have seen X live many times, both in the ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>A12VPEOEZS1KTC</td>\n",
       "      <td>000503860X</td>\n",
       "      <td>I was so excited for this!  Finally, a live co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>ATLZNVLYKP9AZ</td>\n",
       "      <td>000503860X</td>\n",
       "      <td>X is one of the best punk bands ever. I don't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>A3TNYNA2360NPA</td>\n",
       "      <td>000503860X</td>\n",
       "      <td>I've loved X since I first saw them here in Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A2PANT8U0OJNT4</td>\n",
       "      <td>0005419263</td>\n",
       "      <td>The DVD came in great condition and provided l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating         user_id    movie_id   \n",
       "0       5  A3JVF9Y53BEOGC  000503860X  \\\n",
       "1       5  A12VPEOEZS1KTC  000503860X   \n",
       "2       5   ATLZNVLYKP9AZ  000503860X   \n",
       "3       5  A3TNYNA2360NPA  000503860X   \n",
       "4       5  A2PANT8U0OJNT4  0005419263   \n",
       "\n",
       "                                             reviews  \n",
       "0  I have seen X live many times, both in the ear...  \n",
       "1  I was so excited for this!  Finally, a live co...  \n",
       "2  X is one of the best punk bands ever. I don't ...  \n",
       "3  I've loved X since I first saw them here in Sa...  \n",
       "4  The DVD came in great condition and provided l...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/collab_model_revs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f41fbf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2133511 entries, 0 to 2133510\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   rating    int64 \n",
      " 1   user_id   object\n",
      " 2   movie_id  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 48.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns='reviews', axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8230403",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(df[['user_id', 'movie_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf0fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9cc0c96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.9294\n"
     ]
    }
   ],
   "source": [
    "baselinee = BaselineOnly()\n",
    "baselinee.fit(trainset)\n",
    "predictions = baselinee.test(testset)\n",
    "base_pred = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9854c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9187  0.9177  0.9143  0.9161  0.9192  0.9172  0.0018  \n",
      "Fit time          13.15   13.63   13.52   13.32   12.66   13.25   0.34    \n",
      "Test time         4.10    3.74    3.40    3.17    2.95    3.47    0.41    \n",
      "('test_rmse', array([0.91874919, 0.91768868, 0.91429583, 0.91609454, 0.91921596]))\n",
      "('fit_time', (13.146021127700806, 13.625556468963623, 13.51961612701416, 13.316447734832764, 12.663116216659546))\n",
      "('test_time', (4.099060535430908, 3.7391767501831055, 3.396686315536499, 3.1740715503692627, 2.954120635986328))\n",
      "-----------------------\n",
      "0.9172088420568423\n"
     ]
    }
   ],
   "source": [
    "svd_cv = SVD()\n",
    "cv_svd = cross_validate(svd_cv, data, measures=['RMSE'], n_jobs=-1, verbose=True)\n",
    "\n",
    "for i in cv_svd.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_svd['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f67de648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  60 | elapsed:  2.0min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  60 | elapsed:  2.7min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  60 | elapsed:  3.0min remaining:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  60 | elapsed:  3.7min remaining:   11.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.9102883902547211, 'mae': 0.6189911924279894}\n",
      "{'rmse': {'n_factors': 20, 'n_epochs': 20}, 'mae': {'n_factors': 20, 'n_epochs': 40}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  3.8min finished\n"
     ]
    }
   ],
   "source": [
    "params = {'n_factors': [20, 50, 100, 150],\n",
    "          'n_epochs':[10, 20, 40]}\n",
    "g_s_svd = GridSearchCV(SVD,param_grid=params,n_jobs=-1, joblib_verbose=10)\n",
    "g_s_svd.fit(data)\n",
    "\n",
    "print(g_s_svd.best_score)\n",
    "print(g_s_svd.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f5ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9202\n"
     ]
    }
   ],
   "source": [
    "SVD_base = SVD()\n",
    "SVD_base.fit(trainset)\n",
    "predictions = SVD_base.test(testset)\n",
    "SVD_first = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1444e2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9096  0.9085  0.9060  0.9089  0.9096  0.9085  0.0013  \n",
      "Fit time          34.45   34.78   34.53   34.40   34.60   34.55   0.13    \n",
      "Test time         9.63    10.14   9.98    9.92    9.86    9.91    0.17    \n",
      "('test_rmse', array([0.90960273, 0.90850002, 0.90603958, 0.9089005 , 0.90955774]))\n",
      "('fit_time', (34.44675898551941, 34.77713227272034, 34.52870988845825, 34.39724254608154, 34.604445934295654))\n",
      "('test_time', (9.634008169174194, 10.143620729446411, 9.9827721118927, 9.919447898864746, 9.857593297958374))\n",
      "-----------------------\n",
      "0.908520115436667\n"
     ]
    }
   ],
   "source": [
    "svd_pp_cv = SVDpp()\n",
    "cv_svdpp = cross_validate(svd_pp_cv, data, measures=['RMSE'], n_jobs=-1, verbose=True)\n",
    "\n",
    "for i in cv_svdpp.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_svdpp['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e10d8a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "C:\\Users\\raxmo\\anaconda3\\envs\\tensor\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 102 out of 120 | elapsed: 14.8min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 115 out of 120 | elapsed: 19.4min remaining:   50.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.9054603863502747}\n",
      "{'rmse': {'n_factors': 10, 'n_epochs': 20, 'cache_ratings': False}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 20.8min finished\n"
     ]
    }
   ],
   "source": [
    "params = {'n_factors': [10, 20, 50, 100],\n",
    "          'n_epochs': [10, 20, 40],\n",
    "          'cache_ratings': [True, False],\n",
    "         }\n",
    "g_s_svdpp = GridSearchCV(SVDpp,param_grid=params,n_jobs=-1, measures=['RMSE'], joblib_verbose=10)\n",
    "g_s_svdpp.fit(data)\n",
    "\n",
    "print(g_s_svdpp.best_score)\n",
    "print(g_s_svdpp.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d3c3051f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9087\n"
     ]
    }
   ],
   "source": [
    "SVDpp_one = SVDpp(n_factors=10, n_epochs=20)\n",
    "SVDpp_one.fit(trainset)\n",
    "predictions = SVDpp_final.test(testset)\n",
    "SVDpp_first = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e18bf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9074\n"
     ]
    }
   ],
   "source": [
    "SVDpp_final = SVDpp(n_factors=5, n_epochs=20)\n",
    "SVDpp_final.fit(trainset)\n",
    "predictions = SVDpp_final.test(testset)\n",
    "SVDpp_last = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556c192",
   "metadata": {},
   "source": [
    "## Function to return content based on similar users predicted by the final model\n",
    "To use the final model I created the recommend_movies function to give content recommendations to existing users, based on the trained SVDpp collaborative filtering model. It takes an existing user ID, the model, a  DataFrame like my movie and tv meta dataframe, and an optional parameter N (defaulting to 10) to recommend N movies. By predicting user ratings for unseen movies and sorting them in descending order, the function returns the top N movie details, such as titles and ratings, based on user preferences and similarities with other users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "009f4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(trained_model, movie_df, N=5, user_id=None):\n",
    "    \n",
    "    if user_id is None:\n",
    "        all_user_ids = movie_df['user_id'].unique().tolist()\n",
    "        user_id = random.choice(all_user_ids)\n",
    "\n",
    "    user_movies = movie_df[movie_df['user_id'] == user_id]['movie_id'].tolist()\n",
    "    all_movies = movie_df['movie_id'].tolist()\n",
    "    unseen_movies = set(all_movies) - set(user_movies)\n",
    "\n",
    "    predictions = []\n",
    "    for movie_id in unseen_movies:\n",
    "        predicted_rating = trained_model.predict(user_id, movie_id).est\n",
    "        predictions.append({'movie_id': movie_id, 'predicted_rating': predicted_rating})\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    top_N = predictions_df.sort_values('predicted_rating', ascending=False).head(N)\n",
    "    top_N_movie_ids = top_N['movie_id'].tolist()\n",
    "\n",
    "    top_N_movies = movie_df[movie_df['movie_id'].isin(top_N_movie_ids)]\n",
    "    top_N_movies.drop_duplicates(subset=['movie_id'], inplace=True)\n",
    "\n",
    "    top_N_ratings = pd.merge(top_N, top_N_movies, on='movie_id')\n",
    "    \n",
    "    num_movies_reviewed = len(user_movies)\n",
    "    print(f\"The user_id # for these recommendations is {user_id} and they have reviewed {num_movies_reviewed} different Movies &/ TV Shows\")\n",
    "\n",
    "    return top_N_ratings.drop(columns=['user_id', 'rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a0b68fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94324 entries, 0 to 94323\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   genre        94324 non-null  object\n",
      " 1   description  70549 non-null  object\n",
      " 2   title        94324 non-null  object\n",
      " 3   starring     94324 non-null  object\n",
      " 4   movie_id     94324 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# df_movies = pd.read_csv('./data/collab_meta.csv')\n",
    "# df_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d610a98e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2133511 entries, 0 to 2133510\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   rating       int64 \n",
      " 1   user_id      object\n",
      " 2   movie_id     object\n",
      " 3   genre        object\n",
      " 4   description  object\n",
      " 5   title        object\n",
      " 6   starring     object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 113.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# merged_df = pd.merge(df, df_movies, on=\"movie_id\", how=\"left\")\n",
    "# merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f1ab889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.to_csv('./data/collab_merged_df.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc12ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('./data/collab_merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da9c24fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user_id # for these recommendations is A1WHHAHIOC21I5 and they have reviewed 5 different Movies &/ TV Shows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>starring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000ARXF7S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>HBO</td>\n",
       "      <td>&lt;![CDATA[ Dear America: Letters Home from Viet...</td>\n",
       "      <td>Dear America - Letters Home from Vietnam</td>\n",
       "      <td>Tom Berenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004MYOYFC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>\"Mesmerizing\" --The Sun (U.K.) As seen on publ...</td>\n",
       "      <td>Murdoch Mysteries: Season 3</td>\n",
       "      <td>Peter Outerbridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004CWLRHC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Foreign Films</td>\n",
       "      <td>Krister Henriksson. Henning Mankell's Swedish ...</td>\n",
       "      <td>Wallander: Episodes 07 - 09</td>\n",
       "      <td>Krister Henriksson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00404ME0G</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Broadway Musicals</td>\n",
       "      <td>Join us for a rousing celebration of the life ...</td>\n",
       "      <td>Sondheim: The Birthday Concert</td>\n",
       "      <td>Stephen Sondheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000WGTD82</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>Martin Clunes returns as the socially-challeng...</td>\n",
       "      <td>Doc Martin - Series 3 - Complete</td>\n",
       "      <td>Martin Clunes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id  predicted_rating              genre   \n",
       "0  B000ARXF7S               5.0                HBO  \\\n",
       "1  B004MYOYFC               5.0                 TV   \n",
       "2  B004CWLRHC               5.0      Foreign Films   \n",
       "3  B00404ME0G               5.0  Broadway Musicals   \n",
       "4  B000WGTD82               5.0                 TV   \n",
       "\n",
       "                                         description   \n",
       "0  <![CDATA[ Dear America: Letters Home from Viet...  \\\n",
       "1  \"Mesmerizing\" --The Sun (U.K.) As seen on publ...   \n",
       "2  Krister Henriksson. Henning Mankell's Swedish ...   \n",
       "3  Join us for a rousing celebration of the life ...   \n",
       "4  Martin Clunes returns as the socially-challeng...   \n",
       "\n",
       "                                      title            starring  \n",
       "0  Dear America - Letters Home from Vietnam        Tom Berenger  \n",
       "1               Murdoch Mysteries: Season 3   Peter Outerbridge  \n",
       "2               Wallander: Episodes 07 - 09  Krister Henriksson  \n",
       "3            Sondheim: The Birthday Concert    Stephen Sondheim  \n",
       "4          Doc Martin - Series 3 - Complete       Martin Clunes  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = recommend_movies(SVDpp_final, merged_df)\n",
    "recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensor)",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
