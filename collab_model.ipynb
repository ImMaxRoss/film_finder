{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849d49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from surprise.prediction_algorithms import BaselineOnly, SVDpp, SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0dab591a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A2VHSG6TZHU1OB</td>\n",
       "      <td>0001527665</td>\n",
       "      <td>Having lived in West New Guinea (Papua) during...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>A1KM9FNEJ8Q171</td>\n",
       "      <td>0001527665</td>\n",
       "      <td>More than anything, I've been challenged to fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>A38LY2SSHVHRYB</td>\n",
       "      <td>0001527665</td>\n",
       "      <td>This is a great movie for a missionary going i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>AHTYUW2H1276L</td>\n",
       "      <td>0001527665</td>\n",
       "      <td>This movie was in ENGLISH....it was a great su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A3M3HCZLXW0YLF</td>\n",
       "      <td>0001527665</td>\n",
       "      <td>This is a fascinating true story, well acted b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating         user_id    movie_id   \n",
       "0       5  A2VHSG6TZHU1OB  0001527665  \\\n",
       "1       5  A1KM9FNEJ8Q171  0001527665   \n",
       "2       4  A38LY2SSHVHRYB  0001527665   \n",
       "3       5   AHTYUW2H1276L  0001527665   \n",
       "4       5  A3M3HCZLXW0YLF  0001527665   \n",
       "\n",
       "                                             reviews  \n",
       "0  Having lived in West New Guinea (Papua) during...  \n",
       "1  More than anything, I've been challenged to fi...  \n",
       "2  This is a great movie for a missionary going i...  \n",
       "3  This movie was in ENGLISH....it was a great su...  \n",
       "4  This is a fascinating true story, well acted b...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab = pd.read_csv('./data/review_allvid_clean.csv')\n",
    "df_collab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f41fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = df_collab.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21dec1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6224034 entries, 0 to 6224033\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   rating    int64 \n",
      " 1   user_id   object\n",
      " 2   movie_id  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 142.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_col.drop(columns='reviews', axis=1, inplace=True)\n",
    "df_col.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3bdc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_col.drop_duplicates(subset=['user_id', 'movie_id'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bdebba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2170362 entries, 9 to 6224032\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   rating    int64 \n",
      " 1   user_id   object\n",
      " 2   movie_id  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 66.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#df = df_col[df_col['user_id'].isin(df_col['user_id'].value_counts()[df_col['user_id'].value_counts() >= 5].index)]\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6658ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_col.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dab07a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "A3ELQQQZH907O8    5\n",
       "AWC7HXAAVNEAR     5\n",
       "A1PJO0NTSORTRM    5\n",
       "A1SCGKAXSQ19U3    5\n",
       "A2HLF4KO1QMO5B    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_id'].value_counts().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3984ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127613"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a0bbf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95076 entries, 0 to 95075\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   genre        94610 non-null  object\n",
      " 1   description  86140 non-null  object\n",
      " 2   title        95061 non-null  object\n",
      " 3   starring     95076 non-null  object\n",
      " 4   movie_id     95076 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('./data/meta_allvid_clean.csv')\n",
    "movies_df.drop(columns =['english', 'rank'], inplace=True)\n",
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b72d9dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 94595 entries, 0 to 95075\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   genre        94595 non-null  object\n",
      " 1   description  85716 non-null  object\n",
      " 2   title        94595 non-null  object\n",
      " 3   starring     94595 non-null  object\n",
      " 4   movie_id     94595 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "all_vid = df['movie_id'].unique().tolist()\n",
    "df_movies = movies_df[movies_df['movie_id'].isin(all_vid)]\n",
    "df_movies.dropna(subset='genre', inplace=True)\n",
    "df_movies.dropna(subset='title', inplace=True)\n",
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9187b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6031186 entries, 7 to 6224033\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   rating    int64 \n",
      " 1   user_id   object\n",
      " 2   movie_id  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 184.1+ MB\n"
     ]
    }
   ],
   "source": [
    "all_vid2 = df_movies['movie_id'].unique().tolist()\n",
    "df2 = df[df['movie_id'].isin(all_vid2)]\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9148473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2128950 entries, 9 to 6224032\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   rating    int64 \n",
      " 1   user_id   object\n",
      " 2   movie_id  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 65.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#df2.drop_duplicates(subset=['user_id', 'movie_id'], keep='first', inplace=True)\n",
    "df2 = df2[df2['user_id'].isin(df2['user_id'].value_counts()[df2['user_id'].value_counts() >= 5].index)]\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a5a2495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94199"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a85dc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94595"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9811bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "# Index: 2170362 entries, 9 to 6224032\n",
    "# Data columns (total 3 columns):\n",
    "#  #   Column    Dtype \n",
    "# ---  ------    ----- \n",
    "#  0   rating    int64 \n",
    "#  1   user_id   object\n",
    "#  2   movie_id  object\n",
    "# dtypes: int64(1), object(2)\n",
    "# memory usage: 66.2+ MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8230403",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(df2[['user_id', 'movie_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "caf0fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f24e257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.9258\n"
     ]
    }
   ],
   "source": [
    "baselinee = BaselineOnly()\n",
    "baselinee.fit(trainset)\n",
    "predictions = baselinee.test(testset)\n",
    "base_pred = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9854c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9168  0.9179  0.9175  0.9183  0.9205  0.9182  0.0012  \n",
      "Fit time          13.18   13.45   13.56   13.23   12.91   13.26   0.22    \n",
      "Test time         3.76    3.70    3.40    3.24    3.02    3.42    0.28    \n",
      "('test_rmse', array([0.91682687, 0.9178684 , 0.91753398, 0.91826024, 0.92046403]))\n",
      "('fit_time', (13.17979097366333, 13.446223020553589, 13.556465148925781, 13.225394010543823, 12.910300493240356))\n",
      "('test_time', (3.764014482498169, 3.6977412700653076, 3.3994007110595703, 3.237215042114258, 3.0191333293914795))\n",
      "-----------------------\n",
      "0.9181907022099839\n"
     ]
    }
   ],
   "source": [
    "svd_cv = SVD()\n",
    "cv_svd = cross_validate(svd_cv, data, measures=['RMSE'], n_jobs=-1, verbose=True)\n",
    "\n",
    "for i in cv_svd.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_svd['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f67de648",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  65 | elapsed:  1.7min remaining:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  65 | elapsed:  1.7min remaining:    4.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_factors\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m      2\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m60\u001b[39m]}\n\u001b[0;32m      3\u001b[0m g_s_svd \u001b[38;5;241m=\u001b[39m GridSearchCV(SVD,param_grid\u001b[38;5;241m=\u001b[39mparams,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, joblib_verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mg_s_svd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(g_s_svd\u001b[38;5;241m.\u001b[39mbest_score)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(g_s_svd\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\surprise\\model_selection\\search.py:104\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     90\u001b[0m cv \u001b[38;5;241m=\u001b[39m get_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv)\n\u001b[0;32m     92\u001b[0m delayed_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     93\u001b[0m     delayed(fit_and_score)(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 104\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoblib_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mout)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# test_measures_dicts is a list of dict like this:\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# [{'mae': 1, 'rmse': 2}, {'mae': 2, 'rmse': 3} ...]\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# E.g. for 5 splits, the first 5 dicts are for the first param\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# (n_parameters_combinations, n_splits). This way we can easily compute\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# the mean and std dev over all splits or over all param comb.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'n_factors': [10, 20, 50, 100],\n",
    "          'n_epochs':[10, 20, 40, 60]}\n",
    "g_s_svd = GridSearchCV(SVD,param_grid=params,n_jobs=-1, joblib_verbose=10)\n",
    "g_s_svd.fit(data)\n",
    "\n",
    "print(g_s_svd.best_score)\n",
    "print(g_s_svd.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f76a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'n_factors': [10, 20, 50, 100],\n",
    "#           'n_epochs':[10, 20, 40, 60],\n",
    "#          'reg_all': [0.01, 0.02, 0.05, 0.1],\n",
    "#          'lr_all': [0.002, 0.005, 0.01]}\n",
    "# g_s_svd = GridSearchCV(SVD,param_grid=params,n_jobs=-1, joblib_verbose=10)\n",
    "# g_s_svd.fit(data)\n",
    "\n",
    "# print(g_s_svd.best_score)\n",
    "# print(g_s_svd.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f5ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9120\n"
     ]
    }
   ],
   "source": [
    "SVD_base = SVD(n_factors=10, n_epochs=40, random_state=42)\n",
    "SVD_base.fit(trainset)\n",
    "predictions = SVD_base.test(testset)\n",
    "kn_first = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1444e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9065  0.9110  0.9083  0.9098  0.9105  0.9092  0.0017  \n",
      "Fit time          35.20   35.35   35.33   35.29   35.14   35.27   0.08    \n",
      "Test time         10.04   10.01   10.02   9.92    9.85    9.97    0.07    \n",
      "('test_rmse', array([0.90645347, 0.9109963 , 0.90828251, 0.90983874, 0.91046576]))\n",
      "('fit_time', (35.20462965965271, 35.35350322723389, 35.33487033843994, 35.29214549064636, 35.14257192611694))\n",
      "('test_time', (10.04360580444336, 10.00626540184021, 10.02463698387146, 9.91608214378357, 9.84733533859253))\n",
      "-----------------------\n",
      "0.9092073537848441\n"
     ]
    }
   ],
   "source": [
    "svd_pp_cv = SVDpp()\n",
    "cv_svdpp = cross_validate(svd_pp_cv, data, measures=['RMSE'], n_jobs=-1, verbose=True)\n",
    "\n",
    "for i in cv_svdpp.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_svdpp['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1c43e97",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   39.4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_factors\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m],\n\u001b[0;32m      2\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m      3\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_all\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.02\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[0;32m      7\u001b[0m          }\n\u001b[0;32m      8\u001b[0m g_s_svdpp \u001b[38;5;241m=\u001b[39m GridSearchCV(SVDpp,param_grid\u001b[38;5;241m=\u001b[39mparams,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, measures\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m], joblib_verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mg_s_svdpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\surprise\\model_selection\\search.py:104\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     90\u001b[0m cv \u001b[38;5;241m=\u001b[39m get_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv)\n\u001b[0;32m     92\u001b[0m delayed_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     93\u001b[0m     delayed(fit_and_score)(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 104\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoblib_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mout)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# test_measures_dicts is a list of dict like this:\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# [{'mae': 1, 'rmse': 2}, {'mae': 2, 'rmse': 3} ...]\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# E.g. for 5 splits, the first 5 dicts are for the first param\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# (n_parameters_combinations, n_splits). This way we can easily compute\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# the mean and std dev over all splits or over all param comb.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'n_factors': [10, 20, 30, 50],\n",
    "          'n_epochs': [10, 20, 30, 50, 100],\n",
    "          'reg_all': [0.02, 0.05, 0.1],\n",
    "          'cache_ratings': [True, False],\n",
    "          'lr_all': [0.002, 0.005, 0.01],\n",
    "          'verbose':[True]\n",
    "         }\n",
    "g_s_svdpp = GridSearchCV(SVDpp,param_grid=params,n_jobs=-1, measures=['RMSE'], joblib_verbose=10)\n",
    "g_s_svdpp.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39038a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_s_svdpp.best_score)\n",
    "print(g_s_svdpp.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25e18bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9071\n"
     ]
    }
   ],
   "source": [
    "SVDpp_final = SVDpp()\n",
    "SVDpp_final.fit(trainset)\n",
    "predictions = SVDpp_final.test(testset)\n",
    "kn_first = accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "#output for user_id with >3 reviews = 1.0246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4790f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS FUNCTION TO CONFIRM THAT THE REC'S ARE MOVIES THAT HAVE NOT BEEN SEEN BY THE USER\n",
    "\n",
    "\n",
    "\n",
    "# def recommend_movies(user_id, trained_model, movie_df, N=10):\n",
    "#     # Get a list of all movies that the user hasn't seen yet\n",
    "#     user_movies = movie_df[movie_df['user_id'] == user_id]['movie_id'].tolist()\n",
    "#     all_movies = movie_df['movie_id'].tolist()\n",
    "#     unseen_movies = set(all_movies) - set(user_movies)\n",
    "\n",
    "#     # Create a dataframe of predictions for all unseen movies\n",
    "#     predictions = []\n",
    "#     for movie_id in unseen_movies:\n",
    "#         predicted_rating = trained_model.predict(user_id, movie_id).est\n",
    "#         predictions.append({'movie_id': movie_id, 'predicted_rating': predicted_rating})\n",
    "#     predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "#     # Sort predictions by rating and return top N\n",
    "#     top_N = predictions_df.sort_values('predicted_rating', ascending=False).head(N)\n",
    "#     top_N_movie_ids = top_N['movie_id'].tolist()\n",
    "\n",
    "#     # Get the details of the top N movies, including title and rating\n",
    "#     top_N_movies = movie_df[movie_df['movie_id'].isin(top_N_movie_ids)]\n",
    "#     top_N_movies.drop_duplicates(subset=['title'], inplace=True)\n",
    "\n",
    "#     # Merge top N movie ratings with the details dataframe\n",
    "#     top_N_ratings = pd.merge(top_N, top_N_movies, on='movie_id')\n",
    "\n",
    "#     # Return the top N movie details (excluding title)\n",
    "#     return top_N_ratings.drop('title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40432014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user_id, trained_model, movie_df, N=10):\n",
    "    # Get a list of all movies that the user hasn't seen yet\n",
    "    user_movies = movie_df[movie_df['user_id'] == user_id]['movie_id'].tolist()\n",
    "    all_movies = movie_df['movie_id'].tolist()\n",
    "    unseen_movies = set(all_movies) - set(user_movies)\n",
    "\n",
    "    # Create a dataframe of predictions for all unseen movies\n",
    "    predictions = []\n",
    "    for movie_id in unseen_movies:\n",
    "        predicted_rating = trained_model.predict(user_id, movie_id).est\n",
    "        predictions.append({'movie_id': movie_id, 'predicted_rating': predicted_rating})\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    # Sort predictions by rating and return top N\n",
    "    top_N = predictions_df.sort_values('predicted_rating', ascending=False).head(N)\n",
    "    top_N_movie_ids = top_N['movie_id'].tolist()\n",
    "\n",
    "    # Get the details of the top N movies, including title and rating\n",
    "    top_N_movies = movie_df[movie_df['movie_id'].isin(top_N_movie_ids)]\n",
    "    top_N_movies.drop_duplicates(subset=['movie_id'], inplace=True)\n",
    "\n",
    "    # Merge top N movie ratings with the details dataframe\n",
    "    top_N_ratings = pd.merge(top_N, top_N_movies, on='movie_id')\n",
    "\n",
    "    # Return the top N movie details (excluding title)\n",
    "    return top_N_ratings.drop(columns=['user_id', 'rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d610a98e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2128950 entries, 0 to 2128949\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   rating       int64 \n",
      " 1   user_id      object\n",
      " 2   movie_id     object\n",
      " 3   genre        object\n",
      " 4   description  object\n",
      " 5   title        object\n",
      " 6   starring     object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 113.7+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df2, df_movies, on=\"movie_id\", how=\"left\")\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b56ac188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94199"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "daa2b695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['title'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7e8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0104c624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "A1Y393RU0D034C    5\n",
       "A37WWPJPSC1TH0    5\n",
       "A21QW4A2N4MY2J    5\n",
       "APGUOMA4TXA8H     5\n",
       "A2QDPJRVXL7P4F    5\n",
       "A1KNSHHIZJ1WX8    5\n",
       "A2U77U71F6PLX8    5\n",
       "AHS2OHKZBIQL7     5\n",
       "A1ZI18XD5UVUKB    5\n",
       "A1T4UVC1ZDQE9D    5\n",
       "AKRBCQ7GLSSL2     5\n",
       "A26X4ACKD32R2O    5\n",
       "AREE1B6VESH5A     5\n",
       "A3KMUBDWJ92FMM    5\n",
       "A27I9GINWSXPBW    5\n",
       "A3SCJSUDQU0B9M    5\n",
       "A1JP8YZBR95E8L    5\n",
       "A2QV790TPL2BH5    5\n",
       "A1QVOW9O6MQDXL    5\n",
       "A200V67LXY8386    5\n",
       "AFQWINGW8YHTC     5\n",
       "A1SLRCDZXWU7BH    5\n",
       "A3CRZI8WSBTYMH    5\n",
       "A1B2LXLWNA5I8L    5\n",
       "A3KPOPE1SAH8FN    5\n",
       "A3TYOOXDY28OV8    5\n",
       "A29H4NJGHQQJ3     5\n",
       "A1X5COOJ796A84    5\n",
       "AS14NV2O3HL1E     5\n",
       "A1TWZER8QEZETA    5\n",
       "A3F47M9AWV6HCG    5\n",
       "AY0NMW3L1PHAC     5\n",
       "A2A17LRHKN464Q    5\n",
       "A30SII42AWOI10    5\n",
       "A19MBSHIW2HWFY    5\n",
       "A2OFV6HFZP750G    5\n",
       "A3QOE23ZM9P415    5\n",
       "A3KK1IO1W8YCNS    5\n",
       "ALDXNZPGD6C6W     5\n",
       "A3CN9X69R9MR06    5\n",
       "A27SQYT9H4P4GE    5\n",
       "A2OY8H75U4H0Y9    5\n",
       "A3J0BZLWS6N2DI    5\n",
       "A3617HBW5ECI77    5\n",
       "A193XFQ5B6JEHZ    5\n",
       "A1GUQJWB5ZBSJ     5\n",
       "A4T6XG06B7SY7     5\n",
       "A1NTNGBHPB7UJ7    5\n",
       "A2RZGSJ41QDDT1    5\n",
       "A21KTTVGI2S5I7    5\n",
       "A3CALKSYND26P9    5\n",
       "A1MG00BQIIDZV     5\n",
       "AMST19F9D96J3     5\n",
       "A1DU6MWME8DHRV    5\n",
       "A2HLF4KO1QMO5B    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['user_id'].value_counts().tail(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c325d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raxmo\\AppData\\Local\\Temp\\ipykernel_16964\\954166125.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_N_movies.drop_duplicates(subset=['movie_id'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>starring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S1ITA2W</td>\n",
       "      <td>4.994772</td>\n",
       "      <td>All Fox Titles</td>\n",
       "      <td>Based upon the acclaimed comic book and direct...</td>\n",
       "      <td>Kingsman: The Secret Service</td>\n",
       "      <td>Various Artists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630356027X</td>\n",
       "      <td>4.973899</td>\n",
       "      <td>A&amp;E Home Video All A&amp;E Titles</td>\n",
       "      <td>They are the world's most celebrated bodyguard...</td>\n",
       "      <td>Secret Service VHS</td>\n",
       "      <td>Various Artists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0790729628</td>\n",
       "      <td>4.825320</td>\n",
       "      <td>Science Fiction &amp; Fantasy Science Fiction Futu...</td>\n",
       "      <td>The Director's Cut dvd edition of Ridley Scott...</td>\n",
       "      <td>Blade Runner</td>\n",
       "      <td>Harrison Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0029O0ANW</td>\n",
       "      <td>4.814167</td>\n",
       "      <td>HBO</td>\n",
       "      <td>At first glance, Ray Drecker seems like an ord...</td>\n",
       "      <td>Hung: Season 1</td>\n",
       "      <td>Thomas Jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000O5GRXU</td>\n",
       "      <td>4.734966</td>\n",
       "      <td>Movies</td>\n",
       "      <td>Dvd</td>\n",
       "      <td>The Conscientious Objector</td>\n",
       "      <td>Terry Benedict</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id  predicted_rating   \n",
       "0  B00S1ITA2W          4.994772  \\\n",
       "1  630356027X          4.973899   \n",
       "2  0790729628          4.825320   \n",
       "3  B0029O0ANW          4.814167   \n",
       "4  B000O5GRXU          4.734966   \n",
       "\n",
       "                                               genre   \n",
       "0                                     All Fox Titles  \\\n",
       "1                      A&E Home Video All A&E Titles   \n",
       "2  Science Fiction & Fantasy Science Fiction Futu...   \n",
       "3                                                HBO   \n",
       "4                                             Movies   \n",
       "\n",
       "                                         description   \n",
       "0  Based upon the acclaimed comic book and direct...  \\\n",
       "1  They are the world's most celebrated bodyguard...   \n",
       "2  The Director's Cut dvd edition of Ridley Scott...   \n",
       "3  At first glance, Ray Drecker seems like an ord...   \n",
       "4                                                Dvd   \n",
       "\n",
       "                          title         starring  \n",
       "0  Kingsman: The Secret Service  Various Artists  \n",
       "1            Secret Service VHS  Various Artists  \n",
       "2                  Blade Runner    Harrison Ford  \n",
       "3                Hung: Season 1      Thomas Jane  \n",
       "4    The Conscientious Objector   Terry Benedict  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 'A1Y393RU0D034C'\n",
    "recommendations = recommend_movies(user_id, SVDpp_final, merged_df, N=5)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "45896439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>starring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338185</th>\n",
       "      <td>2</td>\n",
       "      <td>A1Y393RU0D034C</td>\n",
       "      <td>B00005JLTN</td>\n",
       "      <td>Science Fiction &amp; Fantasy Science Fiction Futu...</td>\n",
       "      <td>Amid a wave of humans waking up from their 'Ma...</td>\n",
       "      <td>The Matrix Reloaded</td>\n",
       "      <td>Keanu Reeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396911</th>\n",
       "      <td>2</td>\n",
       "      <td>A1Y393RU0D034C</td>\n",
       "      <td>B00006NT1R</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Professionally, the Fisher family owns a Los A...</td>\n",
       "      <td>Six Feet Under - The Complete First Season VHS</td>\n",
       "      <td>Peter Krause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660613</th>\n",
       "      <td>5</td>\n",
       "      <td>A1Y393RU0D034C</td>\n",
       "      <td>B00UNEJ2LQ</td>\n",
       "      <td>Drama</td>\n",
       "      <td>An Israeli woman (Ronit Elkabetz) seeking to f...</td>\n",
       "      <td>Gett: The Trial of Viviane Amsalem</td>\n",
       "      <td>Simon Abkarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702924</th>\n",
       "      <td>4</td>\n",
       "      <td>A1Y393RU0D034C</td>\n",
       "      <td>B00YAZNBTI</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>The events behind Kurt Cobains death as seen t...</td>\n",
       "      <td>Soaked In Bleach</td>\n",
       "      <td>Daniel Roebuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756774</th>\n",
       "      <td>4</td>\n",
       "      <td>A1Y393RU0D034C</td>\n",
       "      <td>B015DFI986</td>\n",
       "      <td>Drama</td>\n",
       "      <td>In a gripping true story, American chess prodi...</td>\n",
       "      <td>Pawn Sacrifice</td>\n",
       "      <td>Tobey Maguire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating         user_id    movie_id   \n",
       "338185        2  A1Y393RU0D034C  B00005JLTN  \\\n",
       "396911        2  A1Y393RU0D034C  B00006NT1R   \n",
       "1660613       5  A1Y393RU0D034C  B00UNEJ2LQ   \n",
       "1702924       4  A1Y393RU0D034C  B00YAZNBTI   \n",
       "1756774       4  A1Y393RU0D034C  B015DFI986   \n",
       "\n",
       "                                                     genre   \n",
       "338185   Science Fiction & Fantasy Science Fiction Futu...  \\\n",
       "396911                                                 HBO   \n",
       "1660613                                              Drama   \n",
       "1702924                                        Documentary   \n",
       "1756774                                              Drama   \n",
       "\n",
       "                                               description   \n",
       "338185   Amid a wave of humans waking up from their 'Ma...  \\\n",
       "396911   Professionally, the Fisher family owns a Los A...   \n",
       "1660613  An Israeli woman (Ronit Elkabetz) seeking to f...   \n",
       "1702924  The events behind Kurt Cobains death as seen t...   \n",
       "1756774  In a gripping true story, American chess prodi...   \n",
       "\n",
       "                                                  title        starring  \n",
       "338185                              The Matrix Reloaded    Keanu Reeves  \n",
       "396911   Six Feet Under - The Complete First Season VHS    Peter Krause  \n",
       "1660613              Gett: The Trial of Viviane Amsalem  Simon Abkarian  \n",
       "1702924                                Soaked In Bleach  Daniel Roebuck  \n",
       "1756774                                  Pawn Sacrifice   Tobey Maguire  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.loc[merged_df['user_id'] == 'A1Y393RU0D034C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1ab889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('./data/collab_model_df.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ca9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensor)",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
